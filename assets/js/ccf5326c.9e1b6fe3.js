"use strict";(self.webpackChunknitcbase=self.webpackChunknitcbase||[]).push([[2329],{3905:(e,t,a)=>{a.d(t,{Zo:()=>u,kt:()=>f});var n=a(7294);function r(e,t,a){return t in e?Object.defineProperty(e,t,{value:a,enumerable:!0,configurable:!0,writable:!0}):e[t]=a,e}function o(e,t){var a=Object.keys(e);if(Object.getOwnPropertySymbols){var n=Object.getOwnPropertySymbols(e);t&&(n=n.filter((function(t){return Object.getOwnPropertyDescriptor(e,t).enumerable}))),a.push.apply(a,n)}return a}function i(e){for(var t=1;t<arguments.length;t++){var a=null!=arguments[t]?arguments[t]:{};t%2?o(Object(a),!0).forEach((function(t){r(e,t,a[t])})):Object.getOwnPropertyDescriptors?Object.defineProperties(e,Object.getOwnPropertyDescriptors(a)):o(Object(a)).forEach((function(t){Object.defineProperty(e,t,Object.getOwnPropertyDescriptor(a,t))}))}return e}function l(e,t){if(null==e)return{};var a,n,r=function(e,t){if(null==e)return{};var a,n,r={},o=Object.keys(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||(r[a]=e[a]);return r}(e,t);if(Object.getOwnPropertySymbols){var o=Object.getOwnPropertySymbols(e);for(n=0;n<o.length;n++)a=o[n],t.indexOf(a)>=0||Object.prototype.propertyIsEnumerable.call(e,a)&&(r[a]=e[a])}return r}var s=n.createContext({}),c=function(e){var t=n.useContext(s),a=t;return e&&(a="function"==typeof e?e(t):i(i({},t),e)),a},u=function(e){var t=c(e.components);return n.createElement(s.Provider,{value:t},e.children)},p={inlineCode:"code",wrapper:function(e){var t=e.children;return n.createElement(n.Fragment,{},t)}},d=n.forwardRef((function(e,t){var a=e.components,r=e.mdxType,o=e.originalType,s=e.parentName,u=l(e,["components","mdxType","originalType","parentName"]),d=c(a),f=r,h=d["".concat(s,".").concat(f)]||d[f]||p[f]||o;return a?n.createElement(h,i(i({ref:t},u),{},{components:a})):n.createElement(h,i({ref:t},u))}));function f(e,t){var a=arguments,r=t&&t.mdxType;if("string"==typeof e||r){var o=a.length,i=new Array(o);i[0]=d;var l={};for(var s in t)hasOwnProperty.call(t,s)&&(l[s]=t[s]);l.originalType=e,l.mdxType="string"==typeof e?e:r,i[1]=l;for(var c=2;c<o;c++)i[c]=a[c];return n.createElement.apply(null,i)}return n.createElement.apply(null,a)}d.displayName="MDXCreateElement"},9618:(e,t,a)=>{a.r(t),a.d(t,{assets:()=>s,contentTitle:()=>i,default:()=>p,frontMatter:()=>o,metadata:()=>l,toc:()=>c});var n=a(7462),r=(a(7294),a(3905));const o={title:"Stage 3 : The Disk Buffer and Catalog Caches(Pending)"},i="The Disk Buffer and Catalog Caches(6 hours)",l={unversionedId:"Roadmap/Stage03",id:"Roadmap/Stage03",title:"Stage 3 : The Disk Buffer and Catalog Caches(Pending)",description:"- Learn about the operations in NITCbase and the XFS interface",source:"@site/docs/Roadmap/Stage03.md",sourceDirName:"Roadmap",slug:"/Roadmap/Stage03",permalink:"/docs/Roadmap/Stage03",draft:!1,tags:[],version:"current",frontMatter:{title:"Stage 3 : The Disk Buffer and Catalog Caches(Pending)"},sidebar:"Roadmap",previous:{title:"Stage 2: Record Blocks and Catalogs",permalink:"/docs/Roadmap/Stage02"}},s={},c=[{value:"Introduction",id:"introduction",level:2},{value:"Disk Buffer",id:"disk-buffer",level:3},{value:"Caches",id:"caches",level:3},{value:"Caching the catalogs",id:"caching-the-catalogs",level:2},{value:"Buffering the disk operations",id:"buffering-the-disk-operations",level:2},{value:"Exercises",id:"exercises",level:2}],u={toc:c};function p(e){let{components:t,...a}=e;return(0,r.kt)("wrapper",(0,n.Z)({},u,a,{components:t,mdxType:"MDXLayout"}),(0,r.kt)("h1",{id:"the-disk-buffer-and-catalog-caches6-hours"},"The Disk Buffer and Catalog Caches(6 hours)"),(0,r.kt)("admonition",{title:"Learning Objectives",type:"note"},(0,r.kt)("ul",{parentName:"admonition"},(0,r.kt)("li",{parentName:"ul"},"Learn about the operations in NITCbase and the XFS interface"),(0,r.kt)("li",{parentName:"ul"},"Learn about the NITCbase architecture"))),(0,r.kt)("h2",{id:"introduction"},"Introduction"),(0,r.kt)("p",null,"We have seen record blocks, the way they are represented on the NITCbase disk, and how to read and write from them. However, disk operations are quite slow and a bottleneck to the efficient functioning of our database. Memory operations are much more efficient, but are subject to space constraints. We should ensure that our system makes optimum use of memory wherever possible to build a fast and responsive database."),(0,r.kt)("h3",{id:"disk-buffer"},"Disk Buffer"),(0,r.kt)("p",null,"Following the ",(0,r.kt)("a",{parentName:"p",href:"https://en.wikipedia.org/wiki/Locality_of_reference"},"principle of locality"),", NITCbase buffers all the disk i/o operations. We will be pre-allocating memory for holding 32 disk blocks in memory at a given time. Whenever a disk block is accessed for the first time, it will be loaded into the buffer. All subsequent operations on that block will be done on that buffer until that disk block is swapped out by a more recently required disk block. All the changes done to the buffer will be commited back to the disk at that point."),(0,r.kt)("p",null,"However, in the present stage, we will not be implementing the write-back functionality. Here, we will modify our disk read operations to work from a buffer instdad of the disk directly."),(0,r.kt)("p",null,"mention about StaticBuffer class"),(0,r.kt)("h3",{id:"caches"},"Caches"),(0,r.kt)("p",null,"Almost all operations on a relation require access to its corresponding relation catalog and attribute catalog entries. We will be pre-allocating memory to cache the catalogs of 12 relations at a given time. The relation and attribute catalog entries for the relation and attribute catalogs are always cached during the running of our database. Cince the values stored in these relations will be frequently used and it's beneficial to avoid the overhead of loading it to memory as required."),(0,r.kt)("h2",{id:"caching-the-catalogs"},"Caching the catalogs"),(0,r.kt)("p",null,"Now, let us modify our program to read the catalog details into the respective caches."),(0,r.kt)("p",null,"load the relation cache, open relation table, and attr cache table"),(0,r.kt)("p",null,"The relation catalog and attribute catalog are always ",(0,r.kt)("em",{parentName:"p"},"open")," and have a rel-id of ",(0,r.kt)("strong",{parentName:"p"},"0")," and ",(0,r.kt)("strong",{parentName:"p"},"1")," respectively. Let's modify our ",(0,r.kt)("inlineCode",{parentName:"p"},"main.cpp")," file to read this data from the cache."),(0,r.kt)("pre",null,(0,r.kt)("code",{parentName:"pre",className:"language-cpp",metastring:"title=main.cpp",title:"main.cpp"},'int main(int argc, char *argv[]) {\n  Disk disk_run;\n\n  for (/* for i = 0 and i = 1*/) {\n    struct RelCatEntry relCatEntry;\n\n    // get the relation catalog entry for rel-id i in relCatEntry\n    // using RelCacheTable::getRelCatEntry()\n\n    printf("Relation: %s\\n", relCatEntry.relName);\n\n    for (/* j = 0 to numAttrs of the relation - 1 */) {\n      struct AttrCatEntry attrCatEntry;\n\n      // get the attribute catalog entry for (rel-id i, attribute offset j)\n      // in attrCatEntry using AttrCacheTable::getAttrCatEntry()\n\n      const char *attrType = (/* check the type of the attribute */) ? "NUM" : "STR";\n      printf("  %s: %s\\n", attrCatEntry.attrName, attrType);\n    }\n    printf("\\n");\n  }\n\n  return 0;\n}\n')),(0,r.kt)("p",null,"On running this program, we should see identical output as you saw in the last for the relations RELCAT and ATTRCAT."),(0,r.kt)("h2",{id:"buffering-the-disk-operations"},"Buffering the disk operations"),(0,r.kt)("p",null,"if possible, update the read operations to use static buffer"),(0,r.kt)("h2",{id:"exercises"},"Exercises"),(0,r.kt)("p",null,"insert questions here"),(0,r.kt)("p",null,(0,r.kt)("strong",{parentName:"p"},"Don't forget to undo your changes and revert the ",(0,r.kt)("inlineCode",{parentName:"strong"},"main.c")," file to it's ",(0,r.kt)("a",{parentName:"strong",href:"https://github.com/Nitcbase/nitcbase/blob/master/main.cpp"},"original state")," before proceeding further.")))}p.isMDXComponent=!0}}]);